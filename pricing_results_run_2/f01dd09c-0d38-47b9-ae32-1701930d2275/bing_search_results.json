{
  "app_name": "Google BigQuery",
  "app_slug": "google-bigquery",
  "search_term": "Find the official pricing page URL for Google BigQuery (google-bigquery.com). Only provide the exact URL to the pricing page, not a summary of pricing information.",
  "timestamp": 1744702256.4059706,
  "response_text": [
    "https://cloud.google.com/bigquery/pricing"
  ],
  "citations": [],
  "extracted_content": [
    {
      "url": "https://cloud.google.com/bigquery/pricing",
      "is_accessible": true,
      "content": "BigQuery is a serverless data analytics platform. You don't need to provision individual instances or virtual machines to use BigQuery. Instead, BigQuery automatically allocates computing resources as you need them. You can also reserve compute capacity ahead of time in the form of _slots_, which represent virtual CPUs. The pricing structure of BigQuery reflects this design.\n\nOverview of BigQuery pricing\n----------------------------\n\nBigQuery pricing has two main components:\n\n*   [**Compute pricing**](https://cloud.google.com/bigquery/pricing#analysis_pricing_models) is the cost to process queries, including SQL queries, user-defined functions, scripts, and certain data manipulation language (DML) and data definition language (DDL) statements.\n    \n*   [**Storage pricing**](https://cloud.google.com/bigquery/pricing#storage) is the cost to store data that you load into BigQuery.\n    \n\nBigQuery charges for other operations, including using [BigQuery Omni](https://cloud.google.com/bigquery/pricing#bqomni), [BigQuery ML](https://cloud.google.com/bigquery/pricing#bqml), [BI Engine](https://cloud.google.com/bigquery/pricing#bi_engine_pricing), and streaming [reads](https://cloud.google.com/bigquery/pricing#data_extraction_pricing) and [writes](https://cloud.google.com/bigquery/pricing#data_ingestion_pricing).\n\nIn addition, BigQuery has [free operations](https://cloud.google.com/bigquery/pricing#free) and a [free usage tier](https://cloud.google.com/bigquery/pricing#free-tier).\n\nEvery project that you create has a billing account attached to it. Any charges incurred by BigQuery jobs run in the project are billed to the attached billing account. BigQuery storage charges are also billed to the attached billing account. You can view BigQuery costs and trends by using the Cloud Billing reports page in the Google Cloud console.\n\n### Compute pricing models\n\nBigQuery offers a choice of two compute pricing models for running queries:\n\n*   [**On-demand pricing**](https://cloud.google.com/bigquery/pricing#on_demand_pricing) (per TiB). With this pricing model, you are charged for the number of bytes processed by each query. The first 1 TiB of query data processed per month is free.\n    \n*   [**Capacity pricing**](https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing) (per slot-hour). With this pricing model, you are charged for compute capacity used to run queries, measured in slots (virtual CPUs) over time. This model takes advantage of [BigQuery editions](https://cloud.google.com/bigquery/docs/editions-intro). You can use the BigQuery autoscaler or purchase slot commitments, which are dedicated capacity that is always available for your workloads, at a lower price.\n    \n\nFor more information about which pricing to choose for your workloads, see [Workload management using Reservations](https://cloud.google.com/bigquery/docs/reservations-workload-management).\n\n### Gemini in BigQuery pricing\n\nSee [Gemini in BigQuery Pricing Overview](https://cloud.google.com/products/gemini/pricing#gemini-in-bigquery-pricing) for information about pricing for Gemini in BigQuery.\n\nOn-demand compute pricing\n-------------------------\n\nBy default, queries are billed using the on-demand (per TiB) pricing model, where you pay for the data scanned by your queries.\n\nWith on-demand pricing, you will generally have access to up to 2,000 concurrent slots, shared among all queries in a single project. Periodically, BigQuery will temporarily burst beyond this limit to accelerate smaller queries. In addition, you might occasionally have fewer slots available if there is a high amount of contention for on-demand capacity in a specific location.\n\nOn-demand (per TiB) query pricing is as follows:\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n### Pricing details\n\nNote the following regarding on-demand (per TiB) query charges:\n\n*   BigQuery uses a [columnar data structure](https://en.wikipedia.org/wiki/Column-oriented_DBMS). You're charged according to the total data processed in the columns you select, and the total data per column is calculated based on the types of data in the column. For more information about how your data size is calculated, see [Estimate query costs](https://cloud.google.com/bigquery/docs/best-practices-costs#estimate-query-costs).\n*   You are charged for queries run against shared data. The data owner is not charged when their data is accessed.\n*   You aren't charged for queries that return an error or for queries that retrieve [results from the cache](https://cloud.google.com/bigquery/docs/cached-results). For [procedural language jobs](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language) this consideration is provided at a per-statement level.\n*   Charges are rounded up to the nearest MB, with a minimum 10\u00a0MB data processed per table referenced by the query, and with a minimum 10\u00a0MB data processed per query.\n*   Canceling a running query job might incur charges up to the full cost for the query if you let the query run to completion.\n*   When you run a query, you're charged according to the data processed in the columns you select, even if you set an explicit `LIMIT` on the results.\n*   [Partitioning](https://cloud.google.com/bigquery/docs/partitioned-tables) and [clustering](https://cloud.google.com/bigquery/docs/clustered-tables) your tables can help reduce the amount of data processed by queries. As a best practice, use partitioning and clustering whenever possible.\n*   On-demand (per TiB) pricing is referred to as analysis pricing on the [Google Cloud SKUs](https://cloud.google.com/skus/?filter=bigquery) page.\n*   When you run a query against a clustered table, and the query includes a filter on the clustered columns, BigQuery uses the filter expression to prune the blocks scanned by the query. This can reduce the number of scanned bytes.\n\nBigQuery provides cost control mechanisms that enable you to cap your query costs. You can set:\n\n*   User-level and project-level [custom cost controls](https://cloud.google.com/bigquery/docs/custom-quotas)\n*   The [maximum bytes billed](https://cloud.google.com/bigquery/docs/best-practices-costs#limit_query_costs_by_restricting_the_number_of_bytes_billed) by a query\n\nFor detailed examples of how to calculate the number of bytes processed, see [Query size calculation](https://cloud.google.com/bigquery/docs/estimate-costs#query_size_calculation).\n\nCapacity compute pricing\n------------------------\n\nBigQuery offers a capacity-based compute pricing model for customers who need additional capacity or prefer a predictable cost for query workloads rather than the on-demand price (per TiB of data processed). The capacity compute model offers pay-as-you-go pricing (with autoscaling) and optional one year and three year commitments that provide discounted prices. You pay for query processing capacity, measured in [slots (virtual CPUs)](https://cloud.google.com/bigquery/docs/slots) over time.\n\nTo enable capacity pricing, use [BigQuery reservations](https://cloud.google.com/bigquery/docs/reservations-intro).\n\nBigQuery slot capacity:\n\n*   is available in 3 editions: Standard, Enterprise, and Enterprise Plus.\n*   applies to query costs, including BigQuery ML, DML, and DDL statements.\n*   does not apply to [storage costs](https://cloud.google.com/bigquery/pricing#storage) or BI Engine costs.\n*   does not apply to streaming inserts and using the [BigQuery Storage API](https://cloud.google.com/bigquery/docs/reference/storage).\n*   can leverage the BigQuery autoscaler.\n*   is billed per second with a one minute minimum.\n\nOptional BigQuery [slot commitments](https://cloud.google.com/bigquery/docs/reservations-intro#commitments):\n\n*   are available for one or three year periods.\n*   are available in Enterprise and Enterprise Plus editions.\n*   are regional capacity. Commitments in one region or multi-region cannot be used in another region or multi-region and cannot be moved.\n*   can be shared across your entire organization. There is no need to buy slot [commitments](https://cloud.google.com/bigquery/docs/reservations-intro#commitments) for every project.\n*   are offered with a 50-slot minimum and increments of 50 slots.\n*   are automatically renewed unless set to cancel at the end of the period.\n\nStandard Edition\n----------------\n\nThe following table shows the cost of slots in Standard edition.\n\nEnterprise Edition\n------------------\n\nThe following table shows the cost of slots in Enterprise edition.\n\nEnterprise Plus Edition\n-----------------------\n\nThe following table shows the cost of slots in Enterprise plus edition.\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\nStorage pricing\n---------------\n\nStorage pricing is the cost to store data that you load into BigQuery. You pay for _active storage_ and _long-term_ storage.\n\n*   **Active storage** includes any table or table partition that has been modified in the last 90 days.\n    \n*   **Long-term storage** includes any table or table partition that has not been modified for 90 consecutive days. The price of storage for that table automatically drops by approximately 50%. There is no difference in performance, durability, or availability between active and long-term storage.\n    \n*   **Metadata storage** includes storage for logical and physical metadata for datasets, tables, partitions, models and functions stored in the BigQuery metastore.\n    \n\nThe first 10 GiB of storage per month is free.\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\nSee the [physical storage documentation](https://cloud.google.com/bigquery/docs/datasets-intro#dataset_storage_billing_models) for eligibility criteria.\n\n### Pricing details\n\nStorage pricing is based on the amount of data stored in your [tables](https://cloud.google.com/bigquery/docs/tables-intro#table_pricing), [temporary session tables](https://cloud.google.com/bigquery/docs/sessions-intro) and [temporary multi-statement tables](https://cloud.google.com/bigquery/docs/multi-statement-queries#storage-pricing). There are no storage charges for [temporary cached query result tables](https://cloud.google.com/bigquery/docs/cached-results).\n\nThe size of the data is calculated based on the data types of the individual columns. For a detailed explanation of how data size is calculated, see [Data size calculation](https://cloud.google.com/bigquery/pricing#data).\n\nStorage pricing is prorated per MiB, per second. For example, if you are using active logical storage in us-central1:\n\n*   For 512 MiB for half a month, you pay $0.00575 USD\n*   For 100 GiB for half a month, you pay $1.15 USD\n*   For 1 TiB for a full month, you pay $23.552 USD\n\nStorage usage is calculated in [gibibytes months (GiB months)](https://en.wikipedia.org/wiki/Gibibyte), where 1\u00a0GiB is 230 bytes (1,024\u00a0MiB). Similarly, 1\u00a0tebibyte (TiB) is 240 bytes (1,024\u00a0GiB). The final usage value is the product of data size in gibibytes and storage use time in months.\n\nIf the data in a table is not modified or deleted within 90 consecutive days, it is billed at the **long-term storage** rate. There is no degradation of performance, durability, availability, or any other functionality when a table is considered long-term storage.\n\nEach partition of a partitioned table is considered separately for long-term storage pricing. If a partition hasn't been modified in the last 90 days, the data in that partition is considered long term storage and is charged at the discounted price.\n\nIf the table is edited, the price reverts back to the regular storage pricing, and the 90-day timer starts counting from zero. Anything that modifies the data in a table resets the timer, including:\n\n| Action | Details |\n| --- | --- |\n| Loading data into a table | Any load or query job that appends data to a destination table or overwrites a destination table. |\n| Copying data into a table | Any copy job appends data to a destination table or overwrites a destination table. |\n| Writing query results to a table | Any query job that appends data to a destination table or overwrites a destination table. |\n| Using data manipulation language (DML) | Using a [DML statement](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-manipulation-language) to modify table data. |\n| Using data definition language (DDL) | Using a [`CREATE OR REPLACE TABLE`](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-definition-language#create_table_statement) statement to replace a table. |\n| Streaming data into the table | Ingesting data using the [`tabledata.insertAll`](https://cloud.google.com/bigquery/docs/reference/rest/v2/tabledata/insertAll) API call. |\n\nAll other actions do not reset the timer, including the following:\n\n*   Querying a table\n*   Creating a view that queries a table\n*   Exporting data from a table\n*   Copying a table (to another destination table)\n*   Patching or updating a [table resource](https://cloud.google.com/bigquery/docs/reference/rest/v2/tables)\n\nFor tables that reach the 90-day threshold during a billing cycle, the price is prorated accordingly.\n\nLong-term storage pricing applies only to BigQuery storage, not to data stored in [external data sources](https://cloud.google.com/bigquery/external-data-sources) such as Bigtable, Cloud Storage, and Google Drive.\n\n### Data size calculation\n\nWhen you load data into BigQuery or query the data, you're charged according to the data size. Data size is calculated based on the size of each column's [data type](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types).\n\nThe size of your stored data and the size of the data processed by your queries is calculated in [gibibytes (GiB)](https://en.wikipedia.org/wiki/Gibibyte), where 1\u00a0GiB is 230 bytes (1,024\u00a0MiB). Similarly, 1\u00a0tebibyte (TiB) is 240 bytes (1,024\u00a0GiB).\n\nFor more information, see [Data type sizes](https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#data_type_sizes).\n\nBigQuery provides a usage based free tier for metadata storage, wherein\n\n*   total\\_metadata\\_storage includes any data stored in the [BigQuery metastore](https://cloud.google.com/bigquery/docs/manage-open-source-metadata)\n*   total\\_bigquery\\_data\\_storage includes any data stored in [BigQuery data storage](https://cloud.google.com/bigquery/docs/datasets-intro#dataset_storage_billing_models)\n*   metadata (%) = total\\_metadata\\_storage / total\\_bigquery\\_data\\_storage\n*   If metadata (%) <\\= 2%, then it is within free tier and is not charged\n*   If metadata (%) \\> 2%, then the amount above the free tier is charged at the rate provided in the table above.\n\nThe metadata free tier allowance is calculated at a per-project level.\n\nData Transfer Service pricing\n-----------------------------\n\nThe BigQuery Data Transfer Service charges monthly on a prorated basis. You are charged as follows:\n\n| Data source | Monthly charge (prorated) | Notes |\n| --- | --- | --- || [Campaign Manager](https://cloud.google.com/bigquery/docs/doubleclick-campaign-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [Cloud Storage](https://cloud.google.com/bigquery/docs/cloud-storage-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [Amazon S3](https://cloud.google.com/bigquery/docs/s3-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers),[2,3](https://cloud.google.com/bigquery/pricing#migrations_from_other_platforms) |\n\n| [Google Ads](https://cloud.google.com/bigquery/docs/adwords-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [Google Ad Manager](https://cloud.google.com/bigquery/docs/doubleclick-publisher-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [Google Merchant Center](https://cloud.google.com/bigquery/docs/merchant-center-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [Google Play](https://cloud.google.com/bigquery/docs/play-transfer) | $25 per unique [Package Name](https://cloud.google.com/bigquery/pricing#google-play-package-name) in the `Installs_country` table.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [Search Ads 360](https://cloud.google.com/bigquery/docs/sa360-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| [YouTube Channel](https://cloud.google.com/bigquery/docs/youtube-channel-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n| [YouTube Content Owner](https://cloud.google.com/bigquery/docs/youtube-content-owner-transfer) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers) |\n\n| Data warehouse | Monthly charge (prorated) | Notes |\n| [Teradata](https://cloud.google.com/bigquery/docs/migration/teradata-overview) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers), [2, 3](https://cloud.google.com/bigquery/pricing#migrations_from_other_platforms), [4](https://cloud.google.com/bigquery/pricing#teradata_migrations) |\n| [Amazon Redshift](https://cloud.google.com/bigquery/docs/migration/redshift-overview) | No charge. BigQuery [Quotas and limits](https://cloud.google.com/bigquery/quotas#load_jobs) apply.\n\n | [1](https://cloud.google.com/bigquery/pricing#all_transfers), [2, 3](https://cloud.google.com/bigquery/pricing#migrations_from_other_platforms) |\n\n| Third-party Connectors | Costs apply | See [5](https://cloud.google.com/bigquery/pricing#third-party_connectors) for more details |\n\n### Notes on transfer pricing\n\n#### All transfers\n\n1\\. After data is transferred to BigQuery, standard BigQuery [storage](https://cloud.google.com/bigquery/pricing#storage) and [query](https://cloud.google.com/bigquery/pricing#on_demand_pricing) pricing applies.\n\n#### Migrations from other platforms\n\n2\\. Extraction, uploading to a Cloud Storage bucket, and loading data into BigQuery is free.\n\n3\\. Costs can be incurred outside of Google Cloud by using the BigQuery Data Transfer Service, such as AWS or Azure data transfer charges.\n\n#### Teradata migrations\n\n4\\. Data is _**not**_ automatically deleted from your Cloud Storage bucket after it is uploaded to BigQuery. Consider deleting the data from your Cloud Storage bucket to avoid additional storage costs. See [Cloud Storage pricing](https://cloud.google.com/storage/pricing).\n\n#### Third-party Connectors\n\n5\\. Costs apply for connectors provided by third-party partners. The pricing model differs for different partners and connectors. For more pricing details, refer to individual connectors when enrolling in [Marketplace](https://cloud.google.com/marketplace).\n\n#### Google Play Package Name\n\nEvery Android app has a unique application ID that looks like a Java package name, such as com.example.myapp. The [Installs](https://support.google.com/googleplay/android-developer/answer/6135870#statistics&zippy=%2Cinstalls) report contains a column of \"Package Name\". The number of unique package names is used for calculating usage of transfers.\n\nEach transfer you create generates one or more runs per day. Package names are only counted on the day a transfer run completes. For example, if a transfer run begins on July 14th but completes on July 15th, the package names are counted on July 15th.\n\nIf a unique package name is encountered in more than one transfer run on a particular day, it is counted only once. Package names are counted separately for different transfer configurations. If a unique package name is encountered in runs for two separate transfer configurations, the package name is counted twice.\n\nIf a package name appeared every day for an entire month, you would be charged the full $25 for that month. Otherwise, if it appeared for a part of the month, the charge would be prorated.\n\nExample#1: If we sync for 1 application - com.smule.singandroid, will it cost us $25 per month + storage price for BigQuery?\n\nThe answer is $25 per month (prorated) + storage/querying costs from BigQuery.\n\nExample#2: If we sync all historic data (for 10 years), will we be charged for 120 months or for 1 month, because we transferred them at once?\n\nThe answer is still $25 per month (prorated) + storage/querying costs from BigQuery, since we charge $25 per unique [Package Name](https://cloud.google.com/bigquery/pricing#google-play-package-name) in the Installs\\_country table, regardless of how many years the historic data goes back to for that unique Package Name.\n\nBigQuery Omni pricing\n---------------------\n\nBigQuery Omni offers the following pricing models depending on your workloads and needs.\n\n**On-Demand compute pricing**\n\nSimilar to BigQuery on-demand analysis model, BigQuery Omni queries, by default are billed using the on-demand (per TiB) pricing model, where you pay for the data scanned by your queries.\n\nWith on-demand pricing, you will generally have access to a large pool of concurrent slots, shared among all queries in a single project. Periodically, BigQuery Omni will temporarily burst beyond this limit to accelerate smaller queries. In addition, you might occasionally have fewer slots available if there is a high amount of contention for on-demand capacity in a specific location.\n\nBigQuery Omni on-demand (per TiB) query pricing is as follows:\n\n| Region | Price per TiB |\n| --- | --- |\n| AWS North Virginia (aws-us-east-1) | $7.82 |\n| Azure North Virginia (azure-eastus2) | $9.13 |\n| AWS Seoul (aws-ap-northeast-2) | $10.00 |\n| AWS Oregon (aws-us-west-2) | $7.82 |\n| AWS Ireland (aws-eu-west-1) | $8.60 |\n| AWS Sydney (aws-ap-southeast-2) | $10.55 |\n| AWS Frankfurt (aws-eu-central-1) | $10.16 |\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n**Pricing details**\n\nThe details and limitations are similar to BigQuery analysis pricing. Note the following regarding on-demand (per TiB) query charges:\n\n*   BigQuery uses a [columnar data structure.](https://en.wikipedia.org/wiki/Column-oriented_DBMS) You're charged according to the total data processed in the columns you select, and the total data per column is calculated based on the types of data in the column. For more information about how your data size is calculated, see [Data size calculation.](https://cloud.google.com/bigquery/pricing#data)\n*   You aren't charged for queries that return an error or for queries that retrieve [results from the cache.](https://cloud.google.com/bigquery/docs/cached-results) For [procedural language jobs](https://cloud.google.com/bigquery/docs/reference/standard-sql/procedural-language) this consideration is provided at a per-statement level.\n*   Charges are rounded up to the nearest MB, with a minimum 10 MB data processed per table referenced by the query, and with a minimum 10 MB data processed per query.\n*   Canceling a running query job might incur charges up to the full cost for the query if you let the query run to completion.\n*   When you run a query, you're charged according to the data processed in the columns you select, even if you set an explicit LIMIT on the results.\n*   [Partitioning](https://cloud.google.com/bigquery/docs/partitioned-tables) and [clustering](https://cloud.google.com/bigquery/docs/clustered-tables) your tables can help reduce the amount of data processed by queries. As a best practice, use partitioning and clustering whenever possible.\n*   On-demand (per TiB) pricing is referred to as analysis pricing on the [Google Cloud SKUs](https://cloud.google.com/skus/?filter=bigquery) page.\n*   When you run a query against a clustered table, and the query includes a filter on the clustered columns, BigQuery uses the filter expression to prune the blocks scanned by the query. This can reduce the number of scanned bytes.\n\nBigQuery provides cost control mechanisms that enable you to cap your query costs. You can set:\n\n*   User-level and project-level [custom cost controls.](https://cloud.google.com/bigquery/docs/custom-quotas)\n*   The [maximum bytes billed](https://cloud.google.com/bigquery/docs/best-practices-costs#limit_query_costs_by_restricting_the_number_of_bytes_billed) by a query\n\n**BigQuery Omni with editions**\n\nBigQuery Omni regions support [BigQuery editions](https://cloud.google.com/bigquery/pricing#editions). At present only Enterprise Edition is supported in Omni regions\n\nThe following table shows the cost of slots in Omni regions\n\nAWS North Virginia (aws-us-east-1)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $7.50 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $6 (billed for 1 year) | 100 |\n| 3 yr commit | $4.50 (billed for 3 years) | 100 |\n\nAzure North Virginia (azure-eastus2)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $8.80 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $7 (billed for 1 year) | 100 |\n| 3 yr commit | $5.30 (billed for 3 years) | 100 |\n\nAWS Seoul (aws-ap-northeast-2)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $9.60 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $7.7 (billed for 1 year) | 100 |\n| 3 yr commit | $5.80 (billed for 3 years) | 100 |\n\nAWS Oregon (aws-us-west-2)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $7.50 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $6.00 (billed for 1 year) | 100 |\n| 3 yr commit | $4.50 (billed for 3 years) | 100 |\n\nAWS Ireland (aws-eu-west-1)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $8.25 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $6.60 (billed for 1 year) | 100 |\n| 3 yr commit | $4.95 (billed for 3 years) | 100 |\n\nAWS Sydney (aws-ap-southeast-2)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $10.13 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $8.10 (billed for 1 year) | 100 |\n| 3 yr commit | $6.08 (billed for 3 years) | 100 |\n\nAWS Frankfurt (aws-eu-central-1)\n\n| Commitment model | Hourly cost | Number of slots |\n| --- | --- | --- |\n| PAYG (no commitment) | $9.75 (billed per second with a 1 minute minimum) | 100 |\n| 1 yr commit | $7.80 (billed for 1 year) | 100 |\n| 3 yr commit | $5.85 (billed for 3 years) | 100 |\n\n**Omni Cross Cloud Data Transfer**\n\nWhen using Omni\u2019s Cross Cloud capabilities (Cross Cloud Transfer, Create Table as Select, Insert Into Select, Cross Cloud Joins, and Cross Cloud Materialized Views) that involve data moving from AWS or Azure to Google Cloud, there will be additional charges for data transfer.\n\nSpecifically for Cross-Cloud Materialized Views, Create Table as Select, Insert Into Select, and Cross Cloud Joins there are no charges during Preview. Starting 29 February 2024, these services will be generally available and you will be charged for data transfer. You will be charged for data transfer only when using any of the above listed services from an AWS or Azure region to a Google Cloud BigQuery region. You will be charged on a per GiB rate based on the amount of data transferred from AWS or Azure to Google Cloud.\n\n| SKU | Billing model | Meter | List price |\n| --- | --- | --- | --- |\n| Cross-cloud data transfer from AWS North Virginia (aws-us-east-1) to Google Cloud North America | usage-based | GiB transferred | $.09 |\n| Cross-cloud data transfer from Azure North Virginia (azure-eastus2) to Google Cloud North America | usage-based | GiB transferred | $.0875 |\n| Cross-cloud data transfer from AWS Seoul (aws-ap-northeast-2) to Google Cloud Asia | usage-based | GiB transferred | $.126 |\n| Cross-cloud data transfer from AWS Oregon (aws-us-west-2) to Google Cloud North America | usage-based | GiB transferred | $.09 |\n| Cross-cloud data transfer from AWS Ireland (aws-eu-west-1) to Google Cloud Europe | usage-based | GiB transferred | $.09 |\n| Cross-cloud data transfer from AWS Sydney (aws-ap-southeast-2) to Google Cloud Oceania | usage-based | GiB transferred | $.114 |\n| Cross-cloud data transfer from AWS Frankfurt (aws-eu-central-1) to Google Cloud Europe | usage-based | GiB transferred | $.09 |\n\n**Omni Managed Storage**\n\nWhen using Omni\u2019s Cross Cloud Materialized Views capability, you will also be charged for creation of local materialized views which is on BigQuery Managed Storage on AWS. You will be charged a per GiB for the amount of physical storage that is used for the local materialized view.\n\n| Operation | Pricing |\n| --- | --- |\n| Active physical storage (aws-us-east-1) | $0.05 per GiB per month |\n| Long-term physical storage (aws-us-east-1) | $0.025 per GiB per month |\n| Active physical storage (azure-eastus2) | $0.05 per GiB per month |\n| Long-term physical storage (azure-eastus2) | $0.025 per GiB per month |\n| Active physical storage (aws-ap-northeast-2) | $0.052 per GiB per month |\n| Long-term physical storage (aws-ap-northeast-2) | $0.026 per GiB per month |\n| Active physical storage (aws-us-west-2) | $0.04 per GiB per month |\n| Long-term physical storage (aws-us-west-2) | $0.02 per GiB per month |\n| Active physical storage (aws-eu-west-1) | $0.044 per GiB per month |\n| Long-term physical storage (aws-eu-west-1) | $0.022 per GiB per month |\n| Active physical storage (aws-ap-southeast-2) | $0.052 per GiB per month |\n| Long-term physical storage (aws-ap-southeast-2) | $0.026 per GiB per month |\n| Active physical storage (aws-eu-central-1) | $0.052 per GiB per month |\n| Long-term physical storage (aws-eu-central-1) | $0.026 per GiB per month |\n\nData ingestion pricing\n----------------------\n\nBigQuery offers two modes of data ingestion:\n\n*   **Batch loading**. [Load source files](https://cloud.google.com/bigquery/docs/batch-loading-data) into one or more BigQuery tables in a single batch operation.\n    \n*   **Streaming**. Stream data one record at a time or in small batches using the [BigQuery Storage Write API](https://cloud.google.com/bigquery/docs/write-api) or the [legacy streaming API](https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery).\n    \n\nFor more information about which mode to choose, see [Introduction to loading data](https://cloud.google.com/bigquery/docs/loading-data).\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n### Pricing details\n\nBy default, you are not charged for batch loading data from Cloud Storage or from local files into BigQuery. Load jobs by default use a shared pool of slots. BigQuery does not make guarantees about the available capacity of this shared pool or the throughput you will see. Alternatively, you can purchase dedicated slots to run load jobs. You are charged [capacity-based pricing](https://cloud.google.com/bigquery/pricing#analysis_pricing_models) for dedicated slots. When load jobs are assigned to a reservation, they lose access to the free pool. For more information, see [Assignments](https://cloud.google.com/bigquery/docs/reservations-intro#assignments).\n\nOnce your data is loaded into BigQuery, it is subject to BigQuery [storage pricing](https://cloud.google.com/bigquery/pricing#storage). If you load data from Cloud Storage, you are charged for storing the data in Cloud Storage. For details, see [Data storage](https://cloud.google.com/storage/pricing#storage-pricing) on the Cloud Storage pricing page.\n\nBigQuery offers the following modes of data extraction:\n\n*   **Batch export**. Use an an [extract job](https://cloud.google.com/bigquery/docs/managing-jobs) to export table data to [Cloud Storage](https://cloud.google.com/bigquery/docs/exporting-data). There is no processing charge for exporting data from a BigQuery table using an extract job.\n    \n*   **Export query results**. Use the [`EXPORT DATA`](https://cloud.google.com/bigquery/docs/reference/standard-sql/export-statements) statement to export query results to [Cloud Storage](https://cloud.google.com/bigquery/docs/exporting-data), [Bigtable](https://cloud.google.com/bigquery/docs/export-to-bigtable), or [Spanner](https://cloud.google.com/bigquery/docs/export-to-spanner). You are billed for the compute cost to process the query statement.\n    \n*   **Streaming reads**. Use the [Storage Read API](https://cloud.google.com/bigquery/docs/reference/storage) to perform high-throughput reads of table data. You are billed for the amount of data read.\n    \n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n### Batch export data transfer pricing\n\nYou are charged for data transfer when you export data in batch from BigQuery to a Cloud Storage bucket or Spanner table in another region, as follows:\n\n| Case | Example | Rate |\n| --- | --- | --- |\n| Export within the same location | From us-east1 to us-east1 | Free |\n| Export from BigQuery US multi-region | From US multi-region to us-central1 (Iowa) | Free |\n| Export from BigQuery US multi-region | From US multi-region to any region (except us-central1 (Iowa)) | See following table |\n| Export from BigQuery EU multi-region | From EU multi-region to europe-west4 (Netherlands) | Free |\n| Export from BigQuery EU multi-region | From EU multi-region to any region (except europe-west4 (Netherlands)) | See following table |\n| Export across locations | From us-east1 to us-central1 | See following table |\n\n| **Source location** | **Destination location** |\n| --- | --- |\n|  | Northern America | Europe | Asia | Indonesia | Oceania | Middle East | Latin America | Africa |\n| Northern America | $0.02/GiB | $0.05/GiB | $0.08/GiB | $0.10/GiB | $0.10/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n| Europe | $0.05/GiB | $0.02/GiB | $0.08/GiB | $0.10/GiB | $0.10/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n| Asia | $0.08/GiB | $0.08/GiB | $0.08/GiB | $0.10/GiB | $0.10/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n| Indonesia | $0.10/GiB | $0.10/GiB | $0.10/GiB | $0.08/GiB | $0.08/GiB | $0.11/GiB | $0.14/GiB | $0.14/GiB |\n| Oceania | $0.10/GiB | $0.10/GiB | $0.10/GiB | $0.08/GiB | $0.08/GiB | $0.11/GiB | $0.14/GiB | $0.14/GiB |\n| Middle East | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.08/GiB | $0.14/GiB | $0.11/GiB |\n| Latin America | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB |\n| Africa | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.14/GiB | $0.14/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n\n### Storage Read API data transfer within Google Cloud\n\n| Case | Examples | Rate |\n| --- | --- | --- |\n| Accessing cached query results from [temporary tables](https://cloud.google.com/bigquery/docs/cached-results#how_cached_results_are_stored) | \n*   Temporary tables \"anonymous dataset\"\n\n | Free |\n| Data reads within the same location | \n\n*   From `us-east1` to `us-east1`\n\n | Free |\n| Data read from a [BigQuery multi-region](https://cloud.google.com/bigquery/docs/locations#multi-regional-locations) to a different BigQuery location, and both locations are on the same continent. | \n\n*   From `us` to `us-east1`\n*   From `eu` to `europe-west1`\n\n | Free |\n| Data read between different locations on the same continent (assuming none of the above free cases apply) | \n\n*   From `us-east1` to `northamerica-northeast1`\n*   From `europe-west1` to `europe-north1`\n\n | $0.01/GiB\\* |\n| Data moves between different continents within Google cloud and neither is Australia. | \n\n*   From `us` to `asia`\n*   From `europe-west1` to `southamerica-east1`\n\n | $0.08 per GiB |\n| Data moves between different continents within Google cloud and one is Australia. | \n\n*   From `us` to `australia-southeast1`\n*   From `australia-southeast1` to `europe-west1`\n\n | $0.15 per GiB |\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n### Storage Read API general network usage\n\n| Monthly Usage | Data Transfer to Worldwide Destinations (excluding Asia & Australia)  \n(per GiB) | Data Transfer to Asia Destinations (excluding China, but including Hong Kong)  \n(per GiB) | Data Transfer to China Destinations (excluding Hong Kong)  \n(per GiB) | Data Transfer to Australia Destinations  \n(per GiB) | Data Transfer in |\n| --- | --- | --- | --- | --- | --- |\n| 0-1 TiB | $0.12 | $0.12 | $0.19 | $0.19 | Free |\n| 1-10 TiB | $0.11 | $0.11 | $0.18 | $0.18 | Free |\n| 10+ TiB | $0.08 | $0.08 | $0.15 | $0.15 | Free |\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\nThe Storage Read API has an on-demand price model. With on-demand pricing, BigQuery charges for the number of bytes processed (also referred to as bytes read). On-demand pricing is solely based on usage, with a bytes read free tier of 300 TiB per month for each billing account. Bytes scanned as part of reads from [temporary tables](https://cloud.google.com/bigquery/docs/cached-results#how_cached_results_are_stored) are free and do not count against the 300TiB free tier. This free bytes read 300 TiB is on the bytes-read component, and does not apply to associated outbound data transfer.\n\nNote the following regarding Storage Read API charges:\n\n*   You are charged according to the total amount of data read. The total data read per column is calculated based on the type of data in the column, and the size of the data is calculated based on the column's data type. For a detailed explanation of how data size is calculated, see [Data size calculation](https://cloud.google.com/bigquery/pricing#data).\n*   You are charged for any data read in a read session even if a `ReadRows` call fails.\n*   If you cancel a `ReadRows` call before the end of the stream is reached, you are charged for any data read before the cancellation. Your charges can include data that was read but not returned to you before the cancellation of the `ReadRows` call.\n*   As a best practice, use partitioned and clustered tables whenever possible. You can reduce the amount of data read by using a `WHERE` clause to prune partitions. For more information, see [Querying partitioned tables](https://cloud.google.com/bigquery/docs/querying-partitioned-tables#querying_partitioned_tables_2).\n*   When using Interconnect, Cloud [Interconnect pricing](https://cloud.google.com/network-connectivity/docs/interconnect/pricing#egress-traffic-from-a-vpc-network-through-an-interconnect-connection_1) applies instead of BigQuery Storage Read API General Network Usage prices.\n\nData replication pricing\n------------------------\n\nBesides copy operations within the same region, BigQuery offers two modes of replicating (copying) data between regions. You can perform a single time copy operation, or use incremental ongoing replication. Your options for copying data across regions include the following: - **Cross-region copy**. One time or scheduled copy of table data to between regions or multi-regions, see [copy datasets](https://cloud.google.com/bigquery/docs/managing-datasets#copy-datasets) or [copy tables](https://cloud.google.com/bigquery/docs/managing-tables#copy_tables_across_regions).\n\n*   **Cross-region replication**. Ongoing, incremental replication of a dataset between two or more different regions or multi-regions, see [cross-region dataset replication](https://cloud.google.com/bigquery/docs/data-replication).\n    \n*   **Cross-region Turbo replication**. High performance, ongoing, incremental replication of a dataset between two or more different regions or multi-regions. Available only with [managed disaster recovery](https://cloud.google.com/bigquery/docs/managed-disaster-recovery).\n    \n\n### Storage for replicated data\n\nReplicated data stored in the destination region or multi-region is charged according to [BigQuery storage pricing](https://cloud.google.com/bigquery/pricing#storage).\n\n### Data transfer pricing for replicated data\n\nYou are charged for data transfer for the volume of data replicated. The use cases and breakdown of data transfer charges are provided as follows:\n\n| Case | Example | Rate |\n| --- | --- | --- |\n| Copy operation within the same location | From us-east1 to us-east1 | \\*\\*Free\\*\\* |\n| Replicate (one time or ongoing incremental) from BigQuery US multi-region | From US multi-region to us-central1 (Iowa) | \\*\\*Free\\*\\* |\n| Replicate from BigQuery US multi-region | From US multi-region to any region (except us-central1 (Iowa)) | See following table |\n| Replicate from BigQuery EU multi-region | From EU multi-region to europe-west4 (Netherlands) | \\*\\*Free\\*\\* |\n| Replicate from BigQuery EU multi-region | From EU multi-region to any region (except europe-west4 (Netherlands)) | See following table |\n| Replicate across locations | From us-east1 to us-central1 | See following table |\n\n| **Source location** | **Destination location** |\n| --- | --- |\n|  | Northern America | Europe | Asia | Indonesia | Oceania | Middle East | Latin America | Africa |\n| Northern America | $0.02/GiB | $0.05/GiB | $0.08/GiB | $0.10/GiB | $0.10/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n| Europe | $0.05/GiB | $0.02/GiB | $0.08/GiB | $0.10/GiB | $0.10/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n| Asia | $0.08/GiB | $0.08/GiB | $0.08/GiB | $0.10/GiB | $0.10/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n| Indonesia | $0.10/GiB | $0.10/GiB | $0.10/GiB | $0.08/GiB | $0.08/GiB | $0.11/GiB | $0.14/GiB | $0.14/GiB |\n| Oceania | $0.10/GiB | $0.10/GiB | $0.10/GiB | $0.08/GiB | $0.08/GiB | $0.11/GiB | $0.14/GiB | $0.14/GiB |\n| Middle East | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.08/GiB | $0.14/GiB | $0.11/GiB |\n| Latin America | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB | $0.14/GiB |\n| Africa | $0.11/GiB | $0.11/GiB | $0.11/GiB | $0.14/GiB | $0.14/GiB | $0.11/GiB | $0.14/GiB | $0.11/GiB |\n\n### Data replication data transfer pricing for Turbo replication\n\n| **Source location** | **Destination location** |\n| --- | --- |\n|  | Northern America | Europe | Asia | Indonesia | Oceania | Middle East | Latin America | Africa |\n| Northern America | $0.04/GiB | $0.10/GiB | $0.16/GiB | $0.20/GiB | $0.20/GiB | $0.22/GiB | $0.28/GiB | $0.22/GiB |\n| Europe | $0.10/GiB | $0.04/GiB | $0.16/GiB | $0.20/GiB | $0.20/GiB | $0.22/GiB | $0.28/GiB | $0.22/GiB |\n| Asia | $0.16/GiB | $0.16/GiB | $0.16/GiB | $0.20/GiB | $0.20/GiB | $0.22/GiB | $0.28/GiB | $0.22/GiB |\n| Indonesia | $0.20/GiB | $0.20/GiB | $0.20/GiB | $0.16/GiB | $0.16/GiB | $0.22/GiB | $0.28/GiB | $0.28/GiB |\n| Oceania | $0.20/GiB | $0.20/GiB | $0.20/GiB | $0.16/GiB | $0.16/GiB | $0.22/GiB | $0.28/GiB | $0.28/GiB |\n| Middle East | $0.22/GiB | $0.22/GiB | $0.22/GiB | $0.22/GiB | $0.22/GiB | $0.16/GiB | $0.28/GiB | $0.22/GiB |\n| Latin America | $0.28/GiB | $0.28/GiB | $0.28/GiB | $0.28/GiB | $0.28/GiB | $0.28/GiB | $0.28/GiB | $0.28/GiB |\n| Africa | $0.22/GiB | $0.22/GiB | $0.22/GiB | $0.28/GiB | $0.28/GiB | $0.22/GiB | $0.28/GiB | $0.22/GiB |\n\nMetastore access charges apply to Hive partitioned tables managed in [BigQuery metastore](https://cloud.google.com/bigquery/docs/about-bqms) accessed from services outside of BigQuery, such as [Dataproc](https://cloud.google.com/dataproc-serverless/docs) or [Compute Engine](https://cloud.google.com/products/compute). Access charges do not apply for accessing any other table metadata, including Apache Iceberg tables and Delta Lake tables managed in BigQuery metastore.\n\nWhen you are reading data from the metastore outside of BigQuery, you will be charged for metadata access via the [BigQuery Read API](https://cloud.google.com/bigquery/pricing#data_extraction_pricing). Similarly, when you are writing data to the metastore outside of BigQuery, you will be charged via the [BigQuery Write API](https://cloud.google.com/bigquery/pricing#data_ingestion_pricing).\n\nIf you are accessing the metastore from BigQuery SQL queries, access charges are included in the query processing charges, whether you are using the on-demand or capacity-based pricing.\n\nNotebook runtime pricing\n------------------------\n\nBigQuery Studio Notebooks rely on a default notebook runtime that uses a [Colab Enterprise runtime](https://cloud.google.com/colab/docs/runtimes) to enable notebook code execution. The default Colab Enterprise runtime consumes compute and disk (both SSD and PD) resources.\n\nBilling for these resources is metered as pay-as-you go slots as outlined below. These slots are billed under the [BigQuery Standard Edition SKU](https://cloud.google.com/skus/sku-groups/bigquery-standard-edition-payg).\n\nNotebooks that use a non-default runtime are billed under [Vertex SKUs](https://cloud.google.com/colab/pricing).\n\nThe default notebook runtime is a Google-provisioned virtual machine (VM) that can run the code in your notebook (IPYNB file). This allows BigQuery customers to execute python script and is not charged after idle time.\n\n\\*The Pay as you go slots, will be metered in the edition that is being used at the project level.\n\nThe default notebook allocates PD and SSD in the background to help users install new data science packages and maintain their work beyond the Python code they execute. Once the PD and SSD is released, you will not see charges.\n\nBigQuery Studio notebook pricing details:\n\n*   Default runtime configuration may change to improve usability. Details can be found [here](https://cloud.google.com/colab/docs/runtimes#default-runtime).\n*   Colab Enterprise runtimes shut down after 180 minutes of inactivity by default. [This page](https://cloud.google.com/colab/docs/idle-shutdown) describes the idle shutdown feature and how to change the default idle shutdown settings or turn the feature off when you create a runtime template.\n\nBigQuery ML pricing\n-------------------\n\nBigQuery ML [models](https://cloud.google.com/bigquery/docs/bigqueryml-intro#overview) can be classified into two different categories: built-in models and external models. BigQuery ML built-in models are trained within BigQuery, such as linear regression, logistic regression, k-means, matrix factorization, PCA, and ARIMA models. The pre trained TimesFM model is also considered a built-in model. BigQuery ML external models are trained utilizing other Google Cloud services, DNN, boosted tree and random forest (which are trained on [Vertex AI](https://cloud.google.com/vertex-ai)) and AutoML models (which are trained on the [Vertex AI Tables backend](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/overview)). BigQuery ML model training pricing is based on the model type and your usage pattern, as well as your pricing model: editions or on-demand. BigQuery ML prediction and evaluation functions are executed within BigQuery ML for all model types, priced as explained below.\n\n### BigQuery ML editions pricing\n\nBigQuery ML is available in Enterprise and Enterprise Plus Editions for customers who prefer a compute capacity (number of slots) based pricing model over the on-demand (number of bytes processed) model. Customers can use Enterprise or Enterprise Plus reservations to use all features of BigQuery ML. BigQuery ML usage will be included in the BigQuery Editions usage.\n\n#### Reservations to create built-in models\n\nBigQuery has three job types for reservation assignment: `QUERY`, `PIPELINE`, and `ML_EXTERNAL`. `QUERY` assignments, which are used for analytical queries, are also used to run `CREATE MODEL` queries for BigQuery ML built-in models. Built-in model training and analytical queries share the same pool of resources in their assigned reservations, and have the same behavior regarding being preemptible, and using idle slots from other reservations.\n\n#### Reservations to create external models\n\nBecause external models are trained outside of BigQuery, these workloads are not preemptible. As a result, to ensure other workloads are not impacted, only reservations with `ML_EXTERNAL` job type assignment can be used for these external jobs. [Reservations workload management](https://cloud.google.com/bigquery/docs/reservations-workload-management) describes how to create reservations for external model training jobs. The slots usage per job is calculated to maintain the price parity between BigQuery slots and external Google Cloud service costs.\n\n### BigQuery ML on-demand pricing\n\nBigQuery ML pricing for on-demand queries depends on the type of operation: model type, model creation, model evaluation, model inspection, or model prediction. For the models that support it, hyperparameter tuning is billed at the same rate as model creation. The cost of the model training associated with hyperparameter tuning is the sum of the cost of all executed trials.\n\nBigQuery ML on-demand pricing is as follows:\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n1 The `CREATE MODEL` statement stops at 50 iterations for iterative models. This applies to both on-demand and editions pricing.\n\n2 For time series models, when auto-arima is enabled for automatic hyper-parameter tuning, multiple candidate models are fitted and evaluated during the training phase. In this case, the number of bytes processed by the input `SELECT` statement is multiplied by the number of candidate models, which can be controlled by the [AUTO\\_ARIMA\\_MAX\\_ORDER](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-time-series#auto_arima_max_order) training option for `ARIMA_PLUS` or the [AUTO\\_ARIMA\\_MAX\\_ORDER](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-multivariate-time-series#auto_arima_max_order) training option for `ARIMA_PLUS_XREG`. This applies to both on-demand and editions pricing. The following notes apply to time series model creation:\n\n*   For single time series forecasting with auto-arima enabled, when `AUTO_ARIMA_MAX_ORDER` is (1, 2, 3, 4, 5), the number of candidate models is (6, 12, 20, 30, 42) respectively if non-seasonal _d_ equals one; otherwise, the number of candidate models is (3, 6, 10, 15, 21).\n    \n*   For multiple time series forecasting using `TIME_SERIES_ID_COL`, the charge is for (6, 12, 20, 30, 42) candidate models when `AUTO_ARIMA_MAX_ORDER` is (1, 2, 3, 4, 5) respectively.\n    \n*   Note that this model selection only applies to model creation. For model evaluation, inspection, and prediction, only the selected model is used, with regular query pricing.\n    \n\n3 See BigQuery ML Remote Model Inference for details.\n\n### BigQuery ML remote model training, inference, and tuning\n\nBigQuery ML lets customers create a remote model that targets a [Vertex AI foundation model](https://cloud.google.com/vertex-ai/generative-ai/docs/learn/models#foundation_model_apis), a Vertex AI online prediction endpoint, or a Cloud AI API, for example Cloud AI Vision API.\n\nThe pricing for BigQuery ML remote model inference has the following parts:\n\n1.  The bytes processed by BigQuery are billed according to standard pricing such as on-demand or editions pricing.\n2.  In addition, costs are incurred for the remote endpoint as follows:\n    \n    | Remote Model types | Inference functions | Pricing |\n    | --- | --- | --- |\n    | Google models hosted on Vertex AI | `ML.GENERATE_TEXT`  \n    `ML.GENERATE_EMBEDDING` | [Generative AI on Vertex AI batch pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing). |\n    | Anthropic Claude models enabled on Vertex AI | `ML.GENERATE_TEXT`  \n     | [Generative AI on Vertex AI pricing](https://cloud.google.com/vertex-ai/generative-ai/pricing#claude-models) |\n    | Open models deployed to Vertex AI | `ML.GENERATE_TEXT`  \n     | [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) |\n    | Vertex AI endpoints | `ML.PREDICT` | [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing) |\n    | Cloud Natural Language API | `ML.UNDERSTAND_TEXT` | [Cloud Natural Language API pricing](https://cloud.google.com/natural-language/pricing) |\n    | Cloud Translation API | `ML.TRANSLATE` | [Cloud Translation API pricing](https://cloud.google.com/translate/pricing) |\n    | Cloud Vision API | `ML.ANNOTATE_IMAGE` | [Cloud Vision API pricing](https://cloud.google.com/vision/pricing) |\n    | Document AI API | `ML.PROCESS_DOCUMENT` | [Document AI API pricing](https://cloud.google.com/vision/pricing) |\n    | Speech-to-Text API | `ML.TRANSCRIBE` | [Speech-to-Text API pricing](https://cloud.google.com/speech-to-text/pricing) |\n    \n\nFor remote endpoint model pricing, you are billed directly by the above services. You may use the billing label billing\\_service = 'bigquery\\_ml' and the billing label bigquery\\_job\\_id to filter the exact charges.\n\n#### LLM supervised tuning costs\n\nWhen using supervised tuning with remote models over Vertex AI LLMs, costs are calculated based on the following:\n\n*   The bytes processed from the training data table specified in the [`AS SELECT` clause](https://cloud.google.com/bigquery/docs/reference/standard-sql/bigqueryml-syntax-create-remote-model#as_select). These charges are billed from BigQuery to your project.\n*   The GPU or TPU usage to tune the LLM. These charges are billed from Vertex AI to your project. For more information, see [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing#custom-trained_models).\n\n### BigQuery ML dry run\n\nDue to the nature of the underlying algorithms of some model types and differences in billing, the bytes processed will not be calculated for some model types until after training is completed due to the complexity of calculating the initial estimate.\n\n### BigQuery ML pricing example\n\nBigQuery ML charges are not itemized separately on your billing statement. For current models, if you have BigQuery Editions, BigQuery ML charges are included.\n\nIf you are using [on-demand](https://cloud.google.com/bigquery/pricing#ml_on_demand_pricing) pricing, BigQuery ML charges are included in the BigQuery analysis (query) charges.\n\nBigQuery ML jobs that perform inspection, evaluation, and prediction operations incur the same charges as on-demand query jobs. Because `CREATE MODEL` queries incur different charges, you must calculate `CREATE MODEL` job costs independently by using the Cloud logging audit logs. Using the audit logs, you can determine the bytes billed by the BigQuery ML service for each BigQuery ML `CREATE MODEL` job. Then, multiply the bytes billed by the appropriate cost for `CREATE MODEL` queries in your regional or multi-regional location.\n\nFor example, to determine the cost of a query job in the `US` that includes a BigQuery ML `CREATE MODEL` statement:\n\n1.  Open the [Cloud Logging](https://console.cloud.google.com/logs/query) page in the Google Cloud console.\n    \n2.  Verify that the product is set to BigQuery.\n    \n3.  Click the drop-down arrow in the \"Filter by label or text search\" box and choose **Convert to advanced filter**. This adds the following text to the filter:\n    \n    ```\n    resource.type=\"bigquery_resource\"\n    ```\n    \n4.  Add the following text on line two below the `resource.type` line:\n    \n    ```\n    protoPayload.serviceData.jobCompletedEvent.job.jobConfiguration.query.statementType=\"CREATE_MODEL\"\n    ```\n    \n5.  To the right of the **Submit Filter** button, choose the appropriate time frame from the drop-down list. For example, choosing **Last 24 hours** would display BigQuery ML `CREATE MODEL` jobs completed in the past 24 hours.\n    \n6.  Click **Submit Filter** to display the jobs completed in the given time window.\n    \n7.  After the data is populated, click **View Options** and choose **Modify custom fields**.\n    \n8.  In the **Add custom fields** dialog, enter:\n    \n    ```\n    protoPayload.serviceData.jobCompletedEvent.job.jobStatistics.totalBilledBytes\n    ```\n    \n9.  Click **Save** to update the results.\n    \n10.  To calculate the charges for the BigQuery ML `CREATE MODEL` job, multiply the bytes billed by the [BigQuery ML on-demand price](https://cloud.google.com/bigquery/pricing#ml_on_demand_pricing). In this example, the `CREATE MODEL` job processed 100873011200 bytes. To calculate the cost of this job in the `US` multi-regional location, divide the billed bytes by the number of bytes per TiB, and multiply it by the model creation cost:\n    \n    `100873011200/1099511627776 x $312.5 = $28.669`\n    \n\nBI Engine pricing\n-----------------\n\n[BI Engine](https://cloud.google.com/bigquery/docs/bi-engine-intro) accelerates SQL queries by caching BigQuery data in memory. The amount of data stored is constrained by the amount of capacity you purchase. To purchase BI Engine capacity, create a BI Engine reservation in the project where queries will be run.\n\nWhen BI Engine accelerates a query, the query stage that reads table data is free. Subsequent stages depend on the type of BigQuery pricing you're using:\n\n*   For [on-demand pricing](https://cloud.google.com/bigquery/pricing#on_demand_pricing), stages that use BI Engine are charged for 0 scanned bytes. Subsequent stages will not incur additional on-demand charges.\n    \n*   For [editions pricing](https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing), the first stage consumes no BigQuery reservation slots. Subsequent stages use slots from the BigQuery reservation.\n    \n\nBI Engine pricing is as follows:\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n### Editions commitment bundle\n\nWhen you are using BigQuery [capacity compute pricing](https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing) with BigQuery editions commitments, you are eligible to receive a limited amount of BI Engine capacity as part of your editions price, at no extra cost, as shown in the following chart. To receive BI Engine capacity at no additional cost, follow the instructions to [reserve capacity](https://cloud.google.com/bigquery/docs/bi-engine-reserve-capacity) in a project within the same organization as your editions reservation. To ensure a particular project\u2019s BI Engine reservation is discounted toward this bundled capacity, there should be some slots assigned to the project. BI Engine reservation in an 'on-demand analysis' project will not be counted towards the free capacity. Free capacity is shown in your Billing Reports as a normal cost, but it is discounted as a \"Spending-Based Discount\".\n\n| Number of slots purchased | No-cost, additional BI Engine capacity (GiB) |\n| --- | --- |\n| 100 | 5 |\n| 500 | 25 |\n| 1000 | 50 |\n| 1500 | 75 |\n| 2000 | 100 (maximum per organization) |\n\nFree operations\n---------------\n\nThe following BigQuery operations are free of charge in every location. [Quotas and limits](https://cloud.google.com/bigquery/quotas) apply to these operations.\n\n| Operation | Details |\n| --- | --- |\n| Batch load data | You are not charged for batch loading data using the shared slot pool. You can also create a reservation using [editions pricing](https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing) for guaranteed capacity. Once the data is loaded into BigQuery, you are charged for storage. For details, see [Batch loading data](https://cloud.google.com/bigquery/docs/batch-loading-data). |\n| Copy data | You are not charged for copying a table, but you do incur charges for storing the new table. For more information, see [Copying an existing table](https://cloud.google.com/bigquery/docs/managing-tables#copy-table). |If you are copying tables across regions, you are charged for [data replication](https://cloud.google.com/bigquery/pricing#data_replication).\n| Export data | You are not charged for exporting data using the shared slot pool, but you do incur charges for storing the data in Cloud Storage. You can also create a reservation using [editions pricing](https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing) for guaranteed capacity. When you use the [EXPORT DATA SQL statement](https://cloud.google.com/bigquery/docs/reference/standard-sql/export-statements#export_data_statement), you are charged for query processing. For details, see [Exporting data](https://cloud.google.com/bigquery/pricing#exporting_data). |\n| Delete operations | You are not charged for deleting datasets or tables, deleting individual table partitions, deleting views, or deleting user-defined functions |\n| Metadata operations | You are not charged for list, get, patch, update, and delete calls. Examples include (but are not limited to): listing datasets, listing table data, updating a dataset's access control list, updating a table's description, or listing user-defined functions in a dataset. [Metadata caching](https://cloud.google.com/bigquery/docs/metadata-caching) operations for BigLake tables aren't included in free operations. |\n\nFree usage tier\n---------------\n\nAs part of the [Google Cloud Free Tier](https://cloud.google.com/free), BigQuery offers some resources free of charge up to a specific limit. These free usage limits are available during and after the free trial period. If you go over these usage limits and are no longer in the free trial period, you will be charged according to the pricing on this page. You can try BigQuery's free tier in the [BigQuery sandbox](https://cloud.google.com/bigquery/docs/sandbox) without a credit card.\n\n| Resource | Monthly free usage limits | Details |\n| --- | --- | --- |\n| Storage | The first 10 GiB per month is free. | BigQuery ML models and training data stored in BigQuery are included in the BigQuery storage free tier. |\n| Queries (analysis) | The first 1 TiB of query data processed per month is free. | BigQuery [Editions pricing](https://cloud.google.com/bigquery/pricing#capacity_compute_analysis_pricing) is also available for high-volume customers that prefer a stable, monthly cost.\n |\n\nFlat-rate pricing\n-----------------\n\n### Flat-rate compute pricing\n\nWhen you use the flat-rate compute pricing model, you purchase dedicated query processing capacity, measured in BigQuery [slots](https://cloud.google.com/bigquery/docs/slots). Your queries consume this capacity, and you are not billed for bytes processed. If your capacity demands exceed your committed capacity, BigQuery will queue up queries, and you will not be charged additional fees.\n\nFlat-rate compute pricing:\n\n*   Applies to query costs, including BigQuery ML, DML, and DDL statements.\n*   Does not apply to [storage costs](https://cloud.google.com/bigquery/pricing#storage) or BI Engine costs.\n*   Does not apply to streaming inserts and using the BigQuery Storage API.\n*   Is purchased as a regional resource. Slot [commitments](https://cloud.google.com/bigquery/docs/reservations-intro#commitments) purchased in one region or multi-region cannot be used in another region or multi-region and cannot be moved.\n*   Is available in per-second (flex), monthly, and annual commitments.\n*   Can be shared across your entire organization. There is no need to buy slot [commitments](https://cloud.google.com/bigquery/docs/reservations-intro#commitments) for every project.\n*   Has a 100-slot minimum and is purchased in increments of 100 slots.\n*   Is billed per second until you cancel the commitment, which can be done at any time after the commitment end date.\n\n#### Monthly flat-rate commitments\n\nThe following table shows the cost of your monthly flat-rate slot commitment. For more information, see [Monthly commitments](https://cloud.google.com/bigquery/docs/reservations-details#monthly_commitments).\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n#### Annual flat-rate commitments\n\nThe following table shows the cost of your annual flate-rate slot commitment. For more information, see [Annual commitments](https://cloud.google.com/bigquery/docs/reservations-details#annual_commitments).\n\nIf you pay in a currency other than USD, the prices listed in your currency on [Cloud Platform SKUs](https://cloud.google.com/skus/) apply.\n\n#### Flex slots: short-term flat-rate commitments\n\nFlex slots are a special commitment type:\n\n*   Commitment duration is only 60 seconds.\n*   You can cancel flex slots any time thereafter.\n*   You are charged only for the seconds your commitment was deployed.\n\nFlex slots are subject to capacity availability. When you attempt to purchase flex slots, success of this purchase is not guaranteed. However, once your commitment purchase is successful, your capacity is guaranteed until you cancel it. For more information, see [flex slots](https://cloud.google.com/bigquery/docs/reservations-details#flex_slots).\n\nThe following table shows the cost of your Flex slot commitment.\n\n### BigQuery Omni flat-rate pricing\n\nBigQuery Omni offers flat-rate pricing which provides a predictable cost for queries. To enable flat-rate pricing, use BigQuery Reservations.\n\nWhen you enroll in flat-rate pricing for BigQuery Omni, you purchase dedicated query processing capacity, measured in slots, on Amazon Web Services or Microsoft Azure. Your queries consume this capacity, and you are not billed for bytes processed.\n\nBigQuery Omni flat-rate pricing:\n\n*   Applies to query costs. Does not apply to [storage costs](https://cloud.google.com/bigquery/pricing#storage).\n*   Slot [commitments](https://cloud.google.com/bigquery/docs/reservations-intro#commitments) are purchased for a single multi-cloud region. Slots purchased in one region cannot be used in another region.\n*   Is available in monthly, and annual commitments. Is billed per second until you cancel the commitment, which can be done at any time after the commitment end date.\n*   Can be shared across your entire organization. There is no need to buy slot [commitments](https://cloud.google.com/bigquery/docs/reservations-intro#commitments) for every project.\n*   Has a 100-slot minimum and is purchased in increments of 100 slots.\n\n#### Monthly flat-rate commitments\n\nThe following table shows the cost of your monthly slot commitment. For more information, see [Monthly commitments](https://cloud.google.com/bigquery/docs/reservations-details#monthly_commitments).\n\n#### Annual flat-rate commitments\n\nThe following table shows the cost of your annual slot commitment. For more information, see [Annual commitments](https://cloud.google.com/bigquery/docs/reservations-details#annual_commitments).\n\n#### Flex slots: short-term commitments\n\nFlex slots are a special commitment type:\n\n*   Commitment duration is only 60 seconds.\n*   You can cancel flex slots any time thereafter.\n*   You are charged only for the seconds your commitment was deployed.\n\nFlex slots on BigQuery Omni are subject to capacity availability on AWS or Azure. When you attempt to purchase flex slots, success of this purchase is not guaranteed. However, once your commitment purchase is successful, your capacity is guaranteed until you cancel it. For more information, see [flex slots](https://cloud.google.com/bigquery/docs/reservations-details#flex_slots).\n\nThe following table shows the cost of your Flex slot commitment.\n\n### BI Engine flat-rate commitment bundle\n\nWhen you are using BigQuery flat-rate slot commitments, you are eligible to receive a limited amount of BI Engine capacity as part of your flat-rate price, at no extra cost, as shown in the following chart. To receive BI Engine capacity at no additional cost, follow the instructions to [reserve capacity](https://cloud.google.com/bigquery/docs/bi-engine-reserve-capacity) in a project within the same organization as your flat-rate reservation. To ensure a particular project's BI Engine reservation is discounted toward this bundled capacity, there should be some slots assigned to the project. A BI Engine reservation in an on-demand compute project don't counted towards free capacity. Free capacity is shown in your [billing reports](https://cloud.google.com/billing/docs/reports) as a normal cost, but it is discounted as a \"Spending-Based Discount\".\n\n| Number of slots purchased | No-cost, additional BI Engine capacity (GiB) |\n| --- | --- |\n| 100 | 5 |\n| 500 | 25 |\n| 1000 | 50 |\n| 1500 | 75 |\n| 2000 | 100 (maximum per organization) |\n\nWhat's next\n-----------\n\n*   For information on analyzing billing data using reports, see [View your billing reports and cost trends](https://cloud.google.com/billing/docs/how-to/reports).\n    \n*   For information on analyzing your billing data in BigQuery, see [Export Cloud Billing data to BigQuery](https://cloud.google.com/billing/docs/how-to/export-data-bigquery).\n    \n*   For information about estimating costs, see [Estimating storage and query costs](https://cloud.google.com/bigquery/docs/estimate-costs).\n    \n*   Read the [BigQuery documentation](https://cloud.google.com/bigquery/docs).\n    \n*   Get started with [BigQuery](https://cloud.google.com/bigquery/docs/quickstarts).\n    \n*   Try the [Pricing calculator](https://cloud.google.com/products/calculator).\n    \n*   Learn about [BigQuery solutions and use cases](https://cloud.google.com/architecture?text=BigQuery).\n\nReview pricing for BigQuery",
      "error": null,
      "pricing_data": {
        "app_id": "google_bigquery",
        "app_name": "Google BigQuery",
        "app_slug": "google-bigquery",
        "pricing_url": "https://cloud.google.com/bigquery/pricing",
        "source_url": null,
        "all_pricing_urls": [
          "https://cloud.google.com/bigquery/pricing"
        ],
        "price_model_type": [
          "PriceModelType.USAGE_BASED",
          "PriceModelType.FREE_TIER"
        ],
        "has_free_tier": true,
        "has_free_trial": false,
        "free_trial_period_days": null,
        "currency": "USD",
        "is_pricing_public": true,
        "pricing_page_accessible": true,
        "pricing_notes": "BigQuery offers a free tier for both compute and storage, with detailed usage-based pricing for additional resources.",
        "pricing_tiers": null,
        "usage_based_pricing": [
          {
            "metric_name": "Compute (On-demand)",
            "unit": "per TiB",
            "base_price": null,
            "tiers": null
          },
          {
            "metric_name": "Compute (Capacity)",
            "unit": "per slot-hour",
            "base_price": null,
            "tiers": null
          },
          {
            "metric_name": "Storage (Active)",
            "unit": "per GiB-month",
            "base_price": 0.023,
            "tiers": null
          },
          {
            "metric_name": "Storage (Long-term)",
            "unit": "per GiB-month",
            "base_price": 0.012,
            "tiers": null
          }
        ],
        "ai_specific_pricing": null,
        "promotional_offers": null,
        "additional_fees": null,
        "extraction_timestamp": "2025-04-15T03:31:03.929991",
        "schema_validated": true,
        "confidence_score": 100,
        "extraction_error": false,
        "json_repaired": false
      },
      "pricing_analyzed": true
    }
  ],
  "results_directory": "pricing_results\\google-bigquery\\20250415_033104"
}